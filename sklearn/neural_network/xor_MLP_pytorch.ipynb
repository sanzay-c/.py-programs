{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "1xNp-n9cYzmK"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# XOR input and output data\n",
        "X = torch.tensor([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=torch.float32)  # Inputs\n",
        "y = torch.tensor([[0], [1], [1], [0]], dtype=torch.float32)             # Outputs"
      ],
      "metadata": {
        "id": "bTLOA2aoZkn6"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the neural network\n",
        "# --- Here, nn.Module is the parent class.\n",
        "#     It's the base class provided by PyTorch for building neural network models.\n",
        "#     By inheriting nn.Module, your XORModel gains all the functionalities,\n",
        "#     PyTorch provides for managing layers, weights, forward passes, and backpropagation.\n",
        "\n",
        "class XORModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(XORModel, self).__init__()\n",
        "    self.hidden = nn.Linear(2, 4)  # Hidden layer (2 inputs, 4 neurons)\n",
        "    self.output = nn.Linear(4, 1) # Output layer (4 neurons to 1 output)\n",
        "    self.sigmoid = nn.Sigmoid()   # Activation function\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.sigmoid(self.hidden(x))  # Apply sigmoid to hidden layer\n",
        "    x = self.sigmoid(self.output(x))  # Apply sigmoid to output layer\n",
        "    return x"
      ],
      "metadata": {
        "id": "d2S-M3LBZnMZ"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the model\n",
        "model = XORModel()"
      ],
      "metadata": {
        "id": "MtXt1xsHbOmf"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss function and optimizer\n",
        "# ---It is a loss function used for binary classification problems,\n",
        "#    where the goal is to predict either 0 or 1 as the output (e.g., yes/no, true/false, etc.).---\n",
        "criterion = nn.BCELoss()  # Binary Cross-Entropy Loss for binary classification\n",
        "\n",
        "# An optimizer adjusts the weights and biases of the model during training, based on the gradients of the loss function.\n",
        "#--- Adam (short for Adaptive Moment Estimation) is a popular optimization algorithm in deep learning.\n",
        "#    It automatically adjusts the learning rate for each parameter during training, making it more efficient and robust for many tasks.\n",
        "#    model.parameters() retrieves all the trainable parameters of the model (weights and biases of all layers).---\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)  # Adam optimizer and lr is the learning rate"
      ],
      "metadata": {
        "id": "nfLZsOsEbRTD"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "epochs = 10000 # number of iterations\n",
        "for epoch in range(epochs):\n",
        "    # Forward pass\n",
        "\n",
        "    # ---The input data X is passed through the model to calculate predictions.\n",
        "    #    model(X) applies the weights, biases, and activation functions in the network to generate predictions.---\n",
        "    predictions = model(X)\n",
        "    # This compares the predicted outputs (predictions) with the actual targets (y) to see how wrong the model's predictions are.\n",
        "    loss = criterion(predictions, y)\n",
        "\n",
        "    # Backward pass and optimization\n",
        "    # --- optimizer.zero_grad():\n",
        "    #     Clears the previous gradients stored in the optimizer. ---\n",
        "    optimizer.zero_grad()  # Clear gradients\n",
        "\n",
        "    # it calculates how each weight contributed to the error, layer by layer.\n",
        "    loss.backward()        # Compute gradients\n",
        "\n",
        "    # optimizer.step(): Updates the weights and biases of the model.\n",
        "    optimizer.step()       # Update weights and biases\n",
        "\n",
        "    # Print loss every 1000 epochs\n",
        "    if (epoch + 1) % 1000 == 0:\n",
        "        print(f'Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GgBLKs_VbViV",
        "outputId": "01b81f27-5361-4b10-d076-6f82238e2ed7"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1000/10000], Loss: 0.0000\n",
            "Epoch [2000/10000], Loss: 0.0000\n",
            "Epoch [3000/10000], Loss: 0.0000\n",
            "Epoch [4000/10000], Loss: 0.0000\n",
            "Epoch [5000/10000], Loss: 0.0000\n",
            "Epoch [6000/10000], Loss: 0.0000\n",
            "Epoch [7000/10000], Loss: 0.0000\n",
            "Epoch [8000/10000], Loss: 0.0000\n",
            "Epoch [9000/10000], Loss: 0.0000\n",
            "Epoch [10000/10000], Loss: 0.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "  # Test the model\n",
        "with torch.no_grad():  # No need to calculate gradients for testing\n",
        "    test_predictions = model(X)\n",
        "    for i in range(len(X)):\n",
        "        print(f\"Input: {X[i].tolist()}, Predicted: {test_predictions[i].item():.2f}, Actual: {y[i].item()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_5wW6mFPbaOU",
        "outputId": "52c2d87a-1539-4084-a204-2451da2fde38"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: [0.0, 0.0], Predicted: 0.00, Actual: 0.0\n",
            "Input: [0.0, 1.0], Predicted: 1.00, Actual: 1.0\n",
            "Input: [1.0, 0.0], Predicted: 1.00, Actual: 1.0\n",
            "Input: [1.0, 1.0], Predicted: 0.00, Actual: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qPakRCXwbfoe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}